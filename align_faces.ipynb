{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd4d9b1-cff1-4888-94f3-d01252b9961e",
   "metadata": {},
   "source": [
    "pip install opencv-python\n",
    "pip install imutils\n",
    "pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc42c60f-6401-4b67-b398-a38177cf7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.face_utils import FaceAligner, rect_to_bb\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3dcd7d4-8ea5-4af4-b409-fcaa05ed323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.face_utils.helpers import FACIAL_LANDMARKS_68_IDXS\n",
    "from imutils.face_utils.helpers import FACIAL_LANDMARKS_5_IDXS\n",
    "from imutils.face_utils.helpers import shape_to_np\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class FaceAligner:\n",
    "\tdef __init__(self, predictor, desiredLeftEye=(0.35, 0.35),\n",
    "\t\tdesiredFaceWidth=256, desiredFaceHeight=None):\n",
    "\t\t# store the facial landmark predictor, desired output left\n",
    "\t\t# eye position, and desired output face width + height\n",
    "\t\tself.predictor = predictor\n",
    "\t\tself.desiredLeftEye = desiredLeftEye\n",
    "\t\tself.desiredFaceWidth = desiredFaceWidth\n",
    "\t\tself.desiredFaceHeight = desiredFaceHeight\n",
    "\n",
    "\t\t# if the desired face height is None, set it to be the\n",
    "\t\t# desired face width (normal behavior)\n",
    "\t\tif self.desiredFaceHeight is None:\n",
    "\t\t\tself.desiredFaceHeight = self.desiredFaceWidth\n",
    "\n",
    "\tdef align(self, image, gray, rect):\n",
    "\t\t# convert the landmark (x, y)-coordinates to a NumPy array\n",
    "\t\tshape = self.predictor(gray, rect)\n",
    "\t\tshape = shape_to_np(shape)\n",
    "\t\t\n",
    "\t\t#simple hack ;)\n",
    "\t\tif (len(shape)==68):\n",
    "\t\t\t# extract the left and right eye (x, y)-coordinates\n",
    "\t\t\t(lStart, lEnd) = FACIAL_LANDMARKS_68_IDXS[\"left_eye\"]\n",
    "\t\t\t(rStart, rEnd) = FACIAL_LANDMARKS_68_IDXS[\"right_eye\"]\n",
    "\t\telse:\n",
    "\t\t\t(lStart, lEnd) = FACIAL_LANDMARKS_5_IDXS[\"left_eye\"]\n",
    "\t\t\t(rStart, rEnd) = FACIAL_LANDMARKS_5_IDXS[\"right_eye\"]\n",
    "\t\t\t\n",
    "\t\tleftEyePts = shape[lStart:lEnd]\n",
    "\t\trightEyePts = shape[rStart:rEnd]\n",
    "\n",
    "\t\t# compute the center of mass for each eye\n",
    "\t\tleftEyeCenter = leftEyePts.mean(axis=0).astype(\"int\")\n",
    "\t\trightEyeCenter = rightEyePts.mean(axis=0).astype(\"int\")\n",
    "\n",
    "\t\t# compute the angle between the eye centroids\n",
    "\t\tdY = rightEyeCenter[1] - leftEyeCenter[1]\n",
    "\t\tdX = rightEyeCenter[0] - leftEyeCenter[0]\n",
    "\t\tangle = np.degrees(np.arctan2(dY, dX)) - 180\n",
    "\n",
    "\t\t# compute the desired right eye x-coordinate based on the\n",
    "\t\t# desired x-coordinate of the left eye\n",
    "\t\tdesiredRightEyeX = 1.0 - self.desiredLeftEye[0]\n",
    "\n",
    "\t\t# determine the scale of the new resulting image by taking\n",
    "\t\t# the ratio of the distance between eyes in the *current*\n",
    "\t\t# image to the ratio of distance between eyes in the\n",
    "\t\t# *desired* image\n",
    "\t\tdist = np.sqrt((dX ** 2) + (dY ** 2))\n",
    "\t\tdesiredDist = (desiredRightEyeX - self.desiredLeftEye[0])\n",
    "\t\tdesiredDist *= self.desiredFaceWidth\n",
    "\t\tscale = desiredDist / dist\n",
    "\n",
    "\t\t# compute center (x, y)-coordinates (i.e., the median point)\n",
    "\t\t# between the two eyes in the input image\n",
    "\t\teyesCenter = (int((leftEyeCenter[0] + rightEyeCenter[0]) // 2),\n",
    "            int((leftEyeCenter[1] + rightEyeCenter[1]) // 2))\n",
    "\n",
    "\t\t# grab the rotation matrix for rotating and scaling the face\n",
    "\t\tM = cv2.getRotationMatrix2D(eyesCenter, angle, scale)\n",
    "\n",
    "\t\t# update the translation component of the matrix\n",
    "\t\ttX = self.desiredFaceWidth * 0.5\n",
    "\t\ttY = self.desiredFaceHeight * self.desiredLeftEye[1]\n",
    "\t\tM[0, 2] += (tX - eyesCenter[0])\n",
    "\t\tM[1, 2] += (tY - eyesCenter[1])\n",
    "\n",
    "\t\t# apply the affine transformation\n",
    "\t\t(w, h) = (self.desiredFaceWidth, self.desiredFaceHeight)\n",
    "\t\toutput = cv2.warpAffine(image, M, (w, h),\n",
    "\t\t\tflags=cv2.INTER_CUBIC)\n",
    "\n",
    "\t\t# return the aligned face\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4660f08-ef48-44ec-aa63-6eb076ae7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_name = \"shape_predictor_68_face_landmarks.dat\"\n",
    "if not os.path.isfile(landmark_name):\n",
    "    landmarks_url = \"https://github.com/italojs/facial-landmarks-recognition/raw/master/shape_predictor_68_face_landmarks.dat\"\n",
    "    out = requests.get(landmarks_url)\n",
    "    open(landmark_name, \"wb\").write(out.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cefabf1-60d0-4685-bba0-f376f99cda4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n",
      "Invalid SOS parameters for sequential JPEG\n"
     ]
    }
   ],
   "source": [
    "paths = glob('original_faces/*')\n",
    "failed_paths = []\n",
    "verbose = False\n",
    "save = True\n",
    "\n",
    "size = 1024\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "fa = FaceAligner(predictor, desiredFaceWidth=size, desiredLeftEye=(.42,.5))\n",
    "\n",
    "for image_path in paths:\n",
    "    try:\n",
    "        # load the input image, resize it, and convert it to grayscale\n",
    "        image = cv2.imread(image_path)\n",
    "        image = imutils.resize(image, width=800)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # show the original input image and detect faces in the grayscale\n",
    "        # image\n",
    "        cv2.imshow(\"Input\", image)\n",
    "        rects = detector(gray, 2)\n",
    "\n",
    "\n",
    "\n",
    "        # loop over the face detections\n",
    "        for rect in rects:\n",
    "            # extract the ROI of the *original* face, then align the face\n",
    "            # using facial landmarks\n",
    "            (x, y, w, h) = rect_to_bb(rect)\n",
    "            faceOrig = imutils.resize(image[y:y + h, x:x + w], width=size)\n",
    "            faceAligned = fa.align(image, gray, rect)\n",
    "            if save:\n",
    "                cv2.imwrite(f'aligned_faces/{os.path.basename(image_path)}', faceAligned)\n",
    "            # display the output images\n",
    "            if verbose:\n",
    "                plt.subplot(1,2,1)\n",
    "                plt.imshow(faceOrig)\n",
    "                plt.subplot(1,2,2)\n",
    "                plt.imshow(faceAligned)\n",
    "                plt.show()\n",
    "    except:\n",
    "        failed_paths.append(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67cd2bcb-3356-4d37-a513-6a0252b9d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture issues to resolve in the future:\n",
    "# buttons as faces\n",
    "# other people\n",
    "capture_issues = ['IMG_0133.JPG', 'cfdc965cee-result-20210822214218.jpeg',\n",
    "                  '20210112_233814.jpg', '20201101_092008.jpg',\n",
    "                  '20201221_105043.jpg', '20210112_233814.jpg',\n",
    "                  '20210325_165212.jpg', '20210423_222337.jpg',\n",
    "                  '20210502_173447.jpg', '20210522_123528.jpg',\n",
    "                  '20210614_183300.jpg', '20210629_184214.jpg',\n",
    "                  '20210804_182126.jpg', '20210808_103300.jpg',\n",
    "                  '20210821_150738.jpg', '20210829_093342.jpg',\n",
    "                  '20210814_171040.jpg', '20210918_144126.jpg',\n",
    "                  '20211019_135415.jpg', '20211128_113632.jpg',\n",
    "                  '20220102_120313.jpg', '20220112_080748~2.jpg',\n",
    "                  '20220217_084519.jpg', '20220227_094625.jpg',\n",
    "                  '20220301_222916.jpg', '20220401_133508.jpg',\n",
    "                  '20220409_201522.jpg', '20220423_135319.jpg',\n",
    "                  '20220522_105855.jpg', '20220529_193704.jpg',\n",
    "                  '20220626_135456.jpg', '20220627_120122.jpg',\n",
    "                  '20220704_121621.jpg', '20220710_120555.jpg',\n",
    "                  '20220728_130711.jpg', '20210313_152341.jpg',\n",
    "                  '20220618_164453.jpg', '20220626_133911.jpg',\n",
    "                 '20220626_135456.jpg', '20220627_120122.jpg',\n",
    "                 '20220702_193708.jpg', '20220704_121621.jpg',\n",
    "                 '20220710_120555.jpg', '20220728_130711.jpg',\n",
    "                 '20220728_205915.jpg', '20220811_183018.jpg',\n",
    "                 '20220828_064758.jpg', '20220829_123706.jpg',\n",
    "                 '20220917_163316.jpg', '20220925_190928.jpg',\n",
    "                 '20221013_190606.jpg', '20221015_142308.jpg',\n",
    "                 '20221019_094022.jpg', '20221029_004046.jpg',\n",
    "                 '20221115_083706.jpg', '20221115_083810.jpg',\n",
    "                 '20221120_182349.jpg', '20221126_121051.jpg']\n",
    "\n",
    "need_to_be_renamed = [\n",
    "               '327766_2110888256203_2015606625_o.jpg',\n",
    "               '13483308_10206732714060887_9206378074821374390_o.jpg',\n",
    "               '13938075_10207037654724213_7700935497558972159_o.jpg',\n",
    "                'IMG_2267.JPG',\n",
    "                'AirBrush_20210330203813.jpg']\n",
    "\n",
    "image_issues = capture_issues + need_to_be_renamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f58a906c-9f95-420c-9a1b-8ebadd13a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sorted([i for i in glob('aligned_faces/*')\n",
    "                 if os.path.basename(i) not in image_issues])\n",
    "frame = cv2.imread(images[0])\n",
    "height, width, layers = frame.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da84bbb-e20a-4eed-aca0-9f99e989c9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "output_filename = 'aligned_faces_video.mp4'\n",
    "fps = 9\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "video = cv2.VideoWriter(output_filename, fourcc, fps, (width,height))\n",
    "for image in images:\n",
    "    video.write(cv2.imread(image))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
