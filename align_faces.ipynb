{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd4d9b1-cff1-4888-94f3-d01252b9961e",
   "metadata": {},
   "source": [
    "pip install opencv-python\n",
    "pip install imutils\n",
    "pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42c60f-6401-4b67-b398-a38177cf7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.face_utils import FaceAligner, rect_to_bb\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import json\n",
    "from PIL import Image, ImageOps\n",
    "from pillow_heif import register_heif_opener\n",
    "\n",
    "register_heif_opener()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742562f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture issues to resolve in the future:\n",
    "def load_array_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        array = [line.strip() for line in f]\n",
    "    print(f\"Data loaded from {filename}\")\n",
    "    return array\n",
    "\n",
    "def save_array_to_file(array, filename):\n",
    "    with open(filename, 'a') as f:\n",
    "        for item in array:\n",
    "            f.write(f\"{item}\\n\")\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "capture_issues = load_array_from_file('capture_issues.txt')\n",
    "need_to_be_renamed = load_array_from_file('needs_to_be_renamed.txt')\n",
    "script_failures = load_array_from_file('script_failures.txt')\n",
    "\n",
    "image_issues = capture_issues + need_to_be_renamed + script_failures\n",
    "\n",
    "# mapping if first rectangle isn't ian\n",
    "rectangle_mapping  = json.load(open('rectangle_mapping.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcd7d4-8ea5-4af4-b409-fcaa05ed323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.face_utils.helpers import FACIAL_LANDMARKS_68_IDXS\n",
    "from imutils.face_utils.helpers import FACIAL_LANDMARKS_5_IDXS\n",
    "from imutils.face_utils.helpers import shape_to_np\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class FaceAligner:\n",
    "\tdef __init__(self, predictor, desiredLeftEye=(0.35, 0.35),\n",
    "\t\tdesiredFaceWidth=256, desiredFaceHeight=None):\n",
    "\t\t# store the facial landmark predictor, desired output left\n",
    "\t\t# eye position, and desired output face width + height\n",
    "\t\tself.predictor = predictor\n",
    "\t\tself.desiredLeftEye = desiredLeftEye\n",
    "\t\tself.desiredFaceWidth = desiredFaceWidth\n",
    "\t\tself.desiredFaceHeight = desiredFaceHeight\n",
    "\n",
    "\t\t# if the desired face height is None, set it to be the\n",
    "\t\t# desired face width (normal behavior)\n",
    "\t\tif self.desiredFaceHeight is None:\n",
    "\t\t\tself.desiredFaceHeight = self.desiredFaceWidth\n",
    "\n",
    "\tdef align(self, image, gray, rect):\n",
    "\t\t# convert the landmark (x, y)-coordinates to a NumPy array\n",
    "\t\tshape = self.predictor(gray, rect)\n",
    "\t\tshape = shape_to_np(shape)\n",
    "\t\t\n",
    "\t\t#simple hack ;)\n",
    "\t\tif (len(shape)==68):\n",
    "\t\t\t# extract the left and right eye (x, y)-coordinates\n",
    "\t\t\t(lStart, lEnd) = FACIAL_LANDMARKS_68_IDXS[\"left_eye\"]\n",
    "\t\t\t(rStart, rEnd) = FACIAL_LANDMARKS_68_IDXS[\"right_eye\"]\n",
    "\t\telse:\n",
    "\t\t\t(lStart, lEnd) = FACIAL_LANDMARKS_5_IDXS[\"left_eye\"]\n",
    "\t\t\t(rStart, rEnd) = FACIAL_LANDMARKS_5_IDXS[\"right_eye\"]\n",
    "\t\t\t\n",
    "\t\tleftEyePts = shape[lStart:lEnd]\n",
    "\t\trightEyePts = shape[rStart:rEnd]\n",
    "\n",
    "\t\t# compute the center of mass for each eye\n",
    "\t\tleftEyeCenter = leftEyePts.mean(axis=0).astype(\"int\")\n",
    "\t\trightEyeCenter = rightEyePts.mean(axis=0).astype(\"int\")\n",
    "\n",
    "\t\t# compute the angle between the eye centroids\n",
    "\t\tdY = rightEyeCenter[1] - leftEyeCenter[1]\n",
    "\t\tdX = rightEyeCenter[0] - leftEyeCenter[0]\n",
    "\t\tangle = np.degrees(np.arctan2(dY, dX)) - 180\n",
    "\n",
    "\t\t# compute the desired right eye x-coordinate based on the\n",
    "\t\t# desired x-coordinate of the left eye\n",
    "\t\tdesiredRightEyeX = 1.0 - self.desiredLeftEye[0]\n",
    "\n",
    "\t\t# determine the scale of the new resulting image by taking\n",
    "\t\t# the ratio of the distance between eyes in the *current*\n",
    "\t\t# image to the ratio of distance between eyes in the\n",
    "\t\t# *desired* image\n",
    "\t\tdist = np.sqrt((dX ** 2) + (dY ** 2))\n",
    "\t\tdesiredDist = (desiredRightEyeX - self.desiredLeftEye[0])\n",
    "\t\tdesiredDist *= self.desiredFaceWidth\n",
    "\t\tscale = desiredDist / dist\n",
    "\n",
    "\t\t# compute center (x, y)-coordinates (i.e., the median point)\n",
    "\t\t# between the two eyes in the input image\n",
    "\t\teyesCenter = (int((leftEyeCenter[0] + rightEyeCenter[0]) // 2),\n",
    "            int((leftEyeCenter[1] + rightEyeCenter[1]) // 2))\n",
    "\n",
    "\t\t# grab the rotation matrix for rotating and scaling the face\n",
    "\t\tM = cv2.getRotationMatrix2D(eyesCenter, angle, scale)\n",
    "\n",
    "\t\t# update the translation component of the matrix\n",
    "\t\ttX = self.desiredFaceWidth * 0.5\n",
    "\t\ttY = self.desiredFaceHeight * self.desiredLeftEye[1]\n",
    "\t\tM[0, 2] += (tX - eyesCenter[0])\n",
    "\t\tM[1, 2] += (tY - eyesCenter[1])\n",
    "\n",
    "\t\t# apply the affine transformation\n",
    "\t\t(w, h) = (self.desiredFaceWidth, self.desiredFaceHeight)\n",
    "\t\toutput = cv2.warpAffine(image, M, (w, h),\n",
    "\t\t\tflags=cv2.INTER_CUBIC)\n",
    "\n",
    "\t\t# return the aligned face\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4660f08-ef48-44ec-aa63-6eb076ae7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_name = \"shape_predictor_68_face_landmarks.dat\"\n",
    "if not os.path.isfile(landmark_name):\n",
    "    landmarks_url = \"https://github.com/italojs/facial-landmarks-recognition/raw/master/shape_predictor_68_face_landmarks.dat\"\n",
    "    out = requests.get(landmarks_url)\n",
    "    open(landmark_name, \"wb\").write(out.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefabf1-60d0-4685-bba0-f376f99cda4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths\n",
    "paths = glob('original_faces/*')\n",
    "# remove MP$\n",
    "paths = [path for path in paths if not path.endswith('MP4')]\n",
    "failed_paths = []\n",
    "verbose = False\n",
    "save = True\n",
    "\n",
    "size = 1024\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "fa = FaceAligner(predictor, desiredFaceWidth=size, desiredLeftEye=(.42,.5))\n",
    "\n",
    "def to_aligned_path(image_path):\n",
    "    aligned_base = f'aligned_faces/{os.path.basename(image_path)}'\n",
    "    aligned_path =  os.path.splitext(aligned_base)[0] + '.jpg'\n",
    "    return aligned_path\n",
    "\n",
    "for image_path in paths:\n",
    "    aligned_path = to_aligned_path(image_path)\n",
    "    base_path = os.path.basename(image_path)\n",
    "    if os.path.isfile(aligned_path) or base_path in image_issues:\n",
    "        continue\n",
    "    try:\n",
    "        # load the input image, resize it, and convert it to grayscale\n",
    "        # load and transform image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = ImageOps.exif_transpose(image)\n",
    "        image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        image = imutils.resize(image, width=800)\n",
    "        print(f'successful load of {image_path}')\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # show the original input image and detect faces in the grayscale\n",
    "        # image\n",
    "        cv2.imshow(\"Input\", image)\n",
    "        rects = detector(gray, 2)\n",
    "\n",
    "        # get correct face detection\n",
    "        rect = rects[rectangle_mapping.get(base_path, 0)]\n",
    "        # extract the ROI of the *original* face, then align the face\n",
    "        # using facial landmarks\n",
    "        (x, y, w, h) = rect_to_bb(rect)\n",
    "        faceOrig = imutils.resize(image[y:y + h, x:x + w], width=size)\n",
    "        faceAligned = fa.align(image, gray, rect)\n",
    "        if save:\n",
    "            cv2.imwrite(aligned_path, faceAligned)\n",
    "        # display the output images\n",
    "        if verbose:\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(faceOrig)\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(faceAligned)\n",
    "            plt.show()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'failed to run {image_path}')\n",
    "        failed_paths.append(image_path)\n",
    "\n",
    "failed_base_paths = [os.path.basename(path) for path in failed_paths]\n",
    "save_array_to_file(failed_base_paths, 'script_failures.txt')\n",
    "image_issues += failed_base_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose=True\n",
    "# image_path = \"original_faces/IMG_7656.HEIC\"\n",
    "# base_path = os.path.basename(image_path)\n",
    "\n",
    "# # load the input image, resize it, and convert it to grayscale\n",
    "# # load and transform image\n",
    "# image = Image.open(image_path).convert('RGB')\n",
    "# image = ImageOps.exif_transpose(image)\n",
    "# image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "# image = imutils.resize(image, width=800)\n",
    "# print(f'successful load of {image_path}')\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# # show the original input image and detect faces in the grayscale\n",
    "# # image\n",
    "# cv2.imshow(\"Input\", image)\n",
    "# rects = detector(gray, 2)\n",
    "\n",
    "# # get correct face detection\n",
    "# rect = rects[rectangle_mapping.get(base_path, 1)]\n",
    "# # extract the ROI of the *original* face, then align the face\n",
    "# # using facial landmarks\n",
    "# (x, y, w, h) = rect_to_bb(rect)\n",
    "# faceOrig = imutils.resize(image[y:y + h, x:x + w], width=size)\n",
    "# faceAligned = fa.align(image, gray, rect)\n",
    "# if save:\n",
    "#     cv2.imwrite(aligned_path, faceAligned)\n",
    "# # display the output images\n",
    "# if verbose:\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.imshow(faceOrig)\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.imshow(faceAligned)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d3268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_taken(path):\n",
    "    exif = Image.open(path).getexif()\n",
    "    if not exif:\n",
    "        print('Image {0} does not have EXIF data.'.format(path))\n",
    "        return None\n",
    "    return exif.get(306)\n",
    "\n",
    "def add_date_to_image(image, date_string):\n",
    "    # Convert date string to desired format\n",
    "    date_obj = datetime.strptime(date_string, \"%Y:%m:%d %H:%M:%S\")\n",
    "    formatted_date = date_obj.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Set text parameters\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1\n",
    "    font_color = (255, 255, 255)  # White color\n",
    "    thickness = 2\n",
    "    \n",
    "    # Get text size\n",
    "    text_size = cv2.getTextSize(formatted_date, font, font_scale, thickness)[0]\n",
    "    \n",
    "    # Set text position (bottom left)\n",
    "    text_x = 10\n",
    "    text_y = image.shape[0] - 10  # 10 pixels from the bottom\n",
    "    \n",
    "    # Add black background for better readability\n",
    "    cv2.rectangle(image, (text_x, text_y - text_size[1] - 10),\n",
    "                  (text_x + text_size[0] + 10, text_y + 10),\n",
    "                  (0, 0, 0), -1)\n",
    "    \n",
    "    # Add text to the image\n",
    "    cv2.putText(image, formatted_date, (text_x + 5, text_y), \n",
    "                font, font_scale, font_color, thickness)\n",
    "    \n",
    "    return image\n",
    "\n",
    "dates = []\n",
    "for path in paths:\n",
    "    if os.path.basename(path) in image_issues:\n",
    "        continue\n",
    "    date = get_date_taken(path)\n",
    "    if date is not None:\n",
    "        dates.append((date, to_aligned_path(path)))\n",
    "# sort the dates\n",
    "dates = sorted(dates, key = lambda x: x[0])\n",
    "\n",
    "# get all image paths\n",
    "image_paths = [i[1] for i in dates]\n",
    "frame = cv2.imread(image_paths[0])\n",
    "height, width, layers = frame.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a video\n",
    "def create_video(output_file_name, fps, date_img_array, add_image=True):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    video = cv2.VideoWriter(output_file_name, fourcc, fps, (width,height))\n",
    "    for date, path in date_img_array:\n",
    "        img = cv2.imread(path)\n",
    "        if add_image:\n",
    "            img_with_date = add_date_to_image(img, date)\n",
    "            video.write(img_with_date)\n",
    "        else:\n",
    "            video.write(img)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()\n",
    "\n",
    "output_filename = 'videos/aligned_faces_video.mp4'\n",
    "fps = 9\n",
    "create_video(output_filename, fps, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce540ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create average photo\n",
    "def create_average_image(image_paths):        \n",
    "    average_image = None\n",
    "    total_images = 0\n",
    "    # Iterate over the rest of the images\n",
    "    for path in image_paths:\n",
    "        # Read the image\n",
    "        image = cv2.imread(path)\n",
    "        try:\n",
    "            image = image.astype(np.float32)\n",
    "            total_images += 1\n",
    "        except:\n",
    "            continue\n",
    "        # Add the image to the average\n",
    "        if average_image is None:\n",
    "            average_image = image\n",
    "        else:\n",
    "            average_image += image\n",
    "    if average_image is not None:\n",
    "        # Divide by the number of images to get the average\n",
    "        average_image /= total_images\n",
    "\n",
    "        # Convert back to 8-bit\n",
    "        average_image = average_image.astype(np.uint8)\n",
    "        return average_image\n",
    "\n",
    "average_image = create_average_image(image_paths)\n",
    "# Save the averaged image\n",
    "cv2.imwrite('average_images/overall_average_image.jpg', average_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e48545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "images_by_year = defaultdict(list)\n",
    "images_by_month = defaultdict(list)\n",
    "images_by_quarter = defaultdict(list)\n",
    "# Iterate over the dates and images\n",
    "for date_str, image_path in dates:\n",
    "    # Parse the date\n",
    "    date = datetime.strptime(date_str, '%Y:%m:%d %H:%M:%S')\n",
    "\n",
    "    # Calculate the quarter\n",
    "    quarter = (date.month - 1) // 3 + 1\n",
    "\n",
    "    year_key = date.year\n",
    "    month_key = (date.year, date.month)\n",
    "    quarter_key = (date.year, f\"Q{quarter}\")\n",
    "    \n",
    "    # Add the image to the appropriate list\n",
    "    images_by_year[year_key].append(image_path)\n",
    "    images_by_month[month_key].append(image_path)\n",
    "    images_by_quarter[quarter_key].append(image_path)\n",
    "\n",
    "    \n",
    "for key, images in images_by_quarter.items():\n",
    "    # Create the output filename\n",
    "    output_filename = 'average_images/{0}_{1}_average_image_{2}images.jpg'.format(key[0], key[1], len(images))\n",
    "    \n",
    "    # Create the average image for the month\n",
    "    average_image = create_average_image(images)\n",
    "    if average_image is not None:\n",
    "        # Save the image\n",
    "        cv2.imwrite(output_filename, average_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511fd6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, images in images_by_year.items():\n",
    "    date_subset = [i for i in dates if i[1] in images]\n",
    "    output_filename = f'videos/{key}_aligned_faces_video.mp4'\n",
    "    if len(date_subset) > 50:\n",
    "        create_video(output_filename, fps, date_subset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f9a611",
   "metadata": {},
   "source": [
    "## Future Explorations\n",
    "URL: https://archive.is/lQXdx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
